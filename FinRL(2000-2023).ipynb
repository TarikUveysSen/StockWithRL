{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ## install finrl library\n",
        "# !pip install plotly==4.4.1\n",
        "# !wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "# !chmod +x /usr/local/bin/orca\n",
        "# !apt-get install xvfb libgtk2.0-0 libgconf-2-4\n",
        "# !pip install wrds\n",
        "# !pip install swig\n",
        "# !pip install -q condacolab\n",
        "# import condacolab\n",
        "# condacolab.install()\n",
        "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "# !pip install PyPortfolioOpt"
      ],
      "metadata": {
        "id": "lehDnZj5j-JW"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ],
      "metadata": {
        "id": "mp2aCaImj-n2"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "metadata": {
        "id": "Jj_Ep9WQkGnl"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = [\"^TNX\", \"XU030.IS\"]"
      ],
      "metadata": {
        "id": "hqAWlTM5mpbL"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = YahooDownloader(start_date = '2000-01-01',\n",
        "                           end_date = '2023-09-20',\n",
        "                           ticker_list = tickers).fetch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh6O7XUAkIcN",
        "outputId": "347c8543-d3e4-42e6-c12e-81ee7bddb00f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (11885, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWdeOEsNmdGM",
        "outputId": "18fb9dff-f888-498f-f1d0-2aa969f8db78"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11885, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZO8BxiBSmfIr",
        "outputId": "39d1bf4e-d44b-4750-de17-32b874a24ac4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open          high           low         close  volume  \\\n",
              "0  2000-01-03      6.498      6.603000      6.498000      6.548000       0   \n",
              "1  2000-01-04  19368.000  22593.099609  19368.000000  22406.000000       0   \n",
              "2  2000-01-04      6.530      6.548000      6.485000      6.485000       0   \n",
              "3  2000-01-05  22406.000  22762.800781  20585.199219  21475.099609       0   \n",
              "4  2000-01-05      6.521      6.599000      6.508000      6.599000       0   \n",
              "\n",
              "        tic  day  \n",
              "0      ^TNX    0  \n",
              "1  XU030.IS    1  \n",
              "2      ^TNX    1  \n",
              "3  XU030.IS    2  \n",
              "4      ^TNX    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93bfcf53-b701-497e-936c-36d13144cccb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>6.498</td>\n",
              "      <td>6.603000</td>\n",
              "      <td>6.498000</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>19368.000</td>\n",
              "      <td>22593.099609</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>6.530</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>22406.000</td>\n",
              "      <td>22762.800781</td>\n",
              "      <td>20585.199219</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>6.521</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>6.508000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93bfcf53-b701-497e-936c-36d13144cccb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93bfcf53-b701-497e-936c-36d13144cccb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93bfcf53-b701-497e-936c-36d13144cccb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f963173-ef51-4b39-bffb-83ac1142f6c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f963173-ef51-4b39-bffb-83ac1142f6c5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f963173-ef51-4b39-bffb-83ac1142f6c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H4dC93Emw47",
        "outputId": "e586722f-8bb8-444d-bb95-1d8a0545f852"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11885 entries, 0 to 11884\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    11885 non-null  object \n",
            " 1   open    11885 non-null  float64\n",
            " 2   high    11885 non-null  float64\n",
            " 3   low     11885 non-null  float64\n",
            " 4   close   11885 non-null  float64\n",
            " 5   volume  11885 non-null  int64  \n",
            " 6   tic     11885 non-null  object \n",
            " 7   day     11885 non-null  int32  \n",
            "dtypes: float64(4), int32(1), int64(1), object(2)\n",
            "memory usage: 696.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])"
      ],
      "metadata": {
        "id": "KNbBebs9nGiD"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZlVtXFOnLZc",
        "outputId": "4724a2c3-5c49-4056-b828-ffa3df72c9ce"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11885 entries, 0 to 11884\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   date    11885 non-null  datetime64[ns]\n",
            " 1   open    11885 non-null  float64       \n",
            " 2   high    11885 non-null  float64       \n",
            " 3   low     11885 non-null  float64       \n",
            " 4   close   11885 non-null  float64       \n",
            " 5   volume  11885 non-null  int64         \n",
            " 6   tic     11885 non-null  object        \n",
            " 7   day     11885 non-null  int32         \n",
            "dtypes: datetime64[ns](1), float64(4), int32(1), int64(1), object(1)\n",
            "memory usage: 696.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = df['date'].dt.strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "bi6FanavnOjr"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(['date','tic'],ignore_index=True)"
      ],
      "metadata": {
        "id": "bMcP9eDTnGBO"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K5DrkLT_nQob",
        "outputId": "f54143bc-4ba9-40bc-9bc0-227eb91e3f42"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open          high           low         close  volume  \\\n",
              "0  2000-01-03      6.498      6.603000      6.498000      6.548000       0   \n",
              "1  2000-01-04  19368.000  22593.099609  19368.000000  22406.000000       0   \n",
              "2  2000-01-04      6.530      6.548000      6.485000      6.485000       0   \n",
              "3  2000-01-05  22406.000  22762.800781  20585.199219  21475.099609       0   \n",
              "4  2000-01-05      6.521      6.599000      6.508000      6.599000       0   \n",
              "\n",
              "        tic  day  \n",
              "0      ^TNX    0  \n",
              "1  XU030.IS    1  \n",
              "2      ^TNX    1  \n",
              "3  XU030.IS    2  \n",
              "4      ^TNX    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8713a63e-1a4f-426c-aff7-c42c41704d0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>6.498</td>\n",
              "      <td>6.603000</td>\n",
              "      <td>6.498000</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>19368.000</td>\n",
              "      <td>22593.099609</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>6.530</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>22406.000</td>\n",
              "      <td>22762.800781</td>\n",
              "      <td>20585.199219</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>6.521</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>6.508000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8713a63e-1a4f-426c-aff7-c42c41704d0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8713a63e-1a4f-426c-aff7-c42c41704d0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8713a63e-1a4f-426c-aff7-c42c41704d0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3278fc4a-a8ec-441a-8cb2-95afc9695493\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3278fc4a-a8ec-441a-8cb2-95afc9695493')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3278fc4a-a8ec-441a-8cb2-95afc9695493 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tic.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vR4hKMqnUx6",
        "outputId": "15bdf419-e518-4533-a9c4-64812298750b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tic\n",
              "^TNX        5959\n",
              "XU030.IS    5926\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to keep only rows where the date is common for all tickers\n",
        "df = df[df.groupby('date')['tic'].transform('nunique') == len(tickers)]"
      ],
      "metadata": {
        "id": "6NfPIOPHnfLL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FVz7FkJnq8r",
        "outputId": "48fdc034-44c7-4192-b89c-62a7a387df4c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11454, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tic.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azLbVENpnom9",
        "outputId": "d53b4eb8-b97a-4306-da15-f8f474832457"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tic\n",
              "XU030.IS    5727\n",
              "^TNX        5727\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iB-T87o_njP7",
        "outputId": "6114da85-4f79-458a-ae1a-bcc906b95301"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date          open          high           low         close  volume  \\\n",
              "1  2000-01-04  19368.000000  22593.099609  19368.000000  22406.000000       0   \n",
              "2  2000-01-04      6.530000      6.548000      6.485000      6.485000       0   \n",
              "3  2000-01-05  22406.000000  22762.800781  20585.199219  21475.099609       0   \n",
              "4  2000-01-05      6.521000      6.599000      6.508000      6.599000       0   \n",
              "5  2000-01-06  21475.099609  22006.800781  19998.500000  20136.500000       0   \n",
              "\n",
              "        tic  day  \n",
              "1  XU030.IS    1  \n",
              "2      ^TNX    1  \n",
              "3  XU030.IS    2  \n",
              "4      ^TNX    2  \n",
              "5  XU030.IS    3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0d7c18b-ba0c-4ae3-8bc4-694678e5c141\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22593.099609</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>6.530000</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>22762.800781</td>\n",
              "      <td>20585.199219</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>6.521000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>6.508000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>22006.800781</td>\n",
              "      <td>19998.500000</td>\n",
              "      <td>20136.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d7c18b-ba0c-4ae3-8bc4-694678e5c141')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0d7c18b-ba0c-4ae3-8bc4-694678e5c141 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0d7c18b-ba0c-4ae3-8bc4-694678e5c141');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51ace0c9-311d-4e3c-a812-81ca585fa66c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51ace0c9-311d-4e3c-a812-81ca585fa66c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51ace0c9-311d-4e3c-a812-81ca585fa66c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Feature Engineering:\n",
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = config.INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG5vciRWojm6",
        "outputId": "583d1a8d-41a3-4a8b-cb57-9cee8b5d1b5c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/finrl/meta/preprocessor/preprocessors.py:106: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2qpTN90o-z6",
        "outputId": "2a19ee16-c0be-4318-8d00-791a8bc0d322"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date            0\n",
              "open            0\n",
              "high            0\n",
              "low             0\n",
              "close           0\n",
              "volume          0\n",
              "tic             0\n",
              "day             0\n",
              "macd            0\n",
              "boll_ub         0\n",
              "boll_lb         0\n",
              "rsi_30          0\n",
              "cci_30          0\n",
              "dx_30           0\n",
              "close_30_sma    0\n",
              "close_60_sma    0\n",
              "turbulence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmS38qQlpFCj",
        "outputId": "9dc5c3fc-1ed0-4034-aaa0-e0105a0e9b51"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11454 entries, 0 to 11453\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   date          11454 non-null  object \n",
            " 1   open          11454 non-null  float64\n",
            " 2   high          11454 non-null  float64\n",
            " 3   low           11454 non-null  float64\n",
            " 4   close         11454 non-null  float64\n",
            " 5   volume        11454 non-null  int64  \n",
            " 6   tic           11454 non-null  object \n",
            " 7   day           11454 non-null  int32  \n",
            " 8   macd          11454 non-null  float64\n",
            " 9   boll_ub       11454 non-null  float64\n",
            " 10  boll_lb       11454 non-null  float64\n",
            " 11  rsi_30        11454 non-null  float64\n",
            " 12  cci_30        11454 non-null  float64\n",
            " 13  dx_30         11454 non-null  float64\n",
            " 14  close_30_sma  11454 non-null  float64\n",
            " 15  close_60_sma  11454 non-null  float64\n",
            " 16  turbulence    11454 non-null  float64\n",
            "dtypes: float64(13), int32(1), int64(1), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "wb1_aoJ4pI5S",
        "outputId": "2f0d3165-5937-4e74-8764-46c653ed83e8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date          open          high           low         close  volume  \\\n",
              "0  2000-01-04  19368.000000  22593.099609  19368.000000  22406.000000       0   \n",
              "1  2000-01-04      6.530000      6.548000      6.485000      6.485000       0   \n",
              "2  2000-01-05  22406.000000  22762.800781  20585.199219  21475.099609       0   \n",
              "3  2000-01-05      6.521000      6.599000      6.508000      6.599000       0   \n",
              "4  2000-01-06  21475.099609  22006.800781  19998.500000  20136.500000       0   \n",
              "\n",
              "        tic  day       macd       boll_ub       boll_lb  rsi_30      cci_30  \\\n",
              "0  XU030.IS    1   0.000000  23257.041762  20624.057847     0.0   66.666667   \n",
              "1      ^TNX    1   0.000000  23257.041762  20624.057847     0.0   66.666667   \n",
              "2  XU030.IS    2 -20.885586  23257.041762  20624.057847     0.0   66.666667   \n",
              "3      ^TNX    2   0.002558      6.703220      6.380780   100.0   66.666667   \n",
              "4  XU030.IS    3 -68.122275  23620.873919  19057.525820     0.0 -100.000000   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma  turbulence  \n",
              "0  100.00000  22406.000000  22406.000000         0.0  \n",
              "1  100.00000      6.485000      6.485000         0.0  \n",
              "2  100.00000  21940.549805  21940.549805         0.0  \n",
              "3  100.00000      6.542000      6.542000         0.0  \n",
              "4   57.40766  21339.199870  21339.199870         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bac5ce21-b790-4c50-9794-67525f786494\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22593.099609</td>\n",
              "      <td>19368.000000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23257.041762</td>\n",
              "      <td>20624.057847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>6.530000</td>\n",
              "      <td>6.548000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23257.041762</td>\n",
              "      <td>20624.057847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>6.485000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>22406.000000</td>\n",
              "      <td>22762.800781</td>\n",
              "      <td>20585.199219</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>2</td>\n",
              "      <td>-20.885586</td>\n",
              "      <td>23257.041762</td>\n",
              "      <td>20624.057847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>21940.549805</td>\n",
              "      <td>21940.549805</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>6.521000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>6.508000</td>\n",
              "      <td>6.599000</td>\n",
              "      <td>0</td>\n",
              "      <td>^TNX</td>\n",
              "      <td>2</td>\n",
              "      <td>0.002558</td>\n",
              "      <td>6.703220</td>\n",
              "      <td>6.380780</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>6.542000</td>\n",
              "      <td>6.542000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>21475.099609</td>\n",
              "      <td>22006.800781</td>\n",
              "      <td>19998.500000</td>\n",
              "      <td>20136.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>XU030.IS</td>\n",
              "      <td>3</td>\n",
              "      <td>-68.122275</td>\n",
              "      <td>23620.873919</td>\n",
              "      <td>19057.525820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>57.40766</td>\n",
              "      <td>21339.199870</td>\n",
              "      <td>21339.199870</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bac5ce21-b790-4c50-9794-67525f786494')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bac5ce21-b790-4c50-9794-67525f786494 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bac5ce21-b790-4c50-9794-67525f786494');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db4786ab-8a40-4012-b1ee-e65098825f4d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db4786ab-8a40-4012-b1ee-e65098825f4d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db4786ab-8a40-4012-b1ee-e65098825f4d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFFMw1z7pxFI",
        "outputId": "f4ca2e35-80f0-452c-d5ae-dbd0bcd841b8"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 2, State Space: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": config.INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "}"
      ],
      "metadata": {
        "id": "R39ZRR5ep2Q_"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ],
      "metadata": {
        "id": "qnl0155VqBYT"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ],
      "metadata": {
        "id": "AwlgdvpaqH4x"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_START_DATE = '2000-01-01'\n",
        "TRAIN_END_DATE = '2018-04-01'\n",
        "TEST_START_DATE = '2018-04-01'\n",
        "TEST_END_DATE = '2023-09-20'"
      ],
      "metadata": {
        "id": "pqBmwZFdqNpC"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rebalance_window = 66 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 22 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window,\n",
        "                 validation_window=validation_window,\n",
        "                 **env_kwargs)"
      ],
      "metadata": {
        "id": "zmse5iCsp7RC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000\n",
        "                 }"
      ],
      "metadata": {
        "id": "JauUo8iGqblC"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6xUuCGGqmsF",
        "outputId": "385a33f2-a105-4728-e6ab-0694da7de3a0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mGörüntülenen çıkış son 5000 satıra kısaltıldı.\u001b[0m\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.87      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -0.489     |\n",
            "|    reward             | 0.48816115 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0342     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 224        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.86      |\n",
            "|    explained_variance | 0.0261     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -0.399     |\n",
            "|    reward             | -0.7822653 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.234      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 225         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.86       |\n",
            "|    explained_variance | -0.26       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 4.22        |\n",
            "|    reward             | -0.14264576 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.79        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 222        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.86      |\n",
            "|    explained_variance | 0.0381     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -0.165     |\n",
            "|    reward             | -0.5725004 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0367     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 218          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.156       |\n",
            "|    reward             | 0.0035664774 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.00658      |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2020-03-02 to  2020-04-01\n",
            "A2C Sharpe Ratio:  -0.7684407939830722\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_550_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 257          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 7            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | -0.032454334 |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 286          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035612718 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00657     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 17.9         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    reward               | -0.028702758 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 29.9         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 260           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 23            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0059552365  |\n",
            "|    clip_fraction        | 0.0336        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | -0.00124      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 6.63          |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.00257      |\n",
            "|    reward               | -0.0058576777 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 8.74          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 257         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004444671 |\n",
            "|    clip_fraction        | 0.0257      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | -0.0234     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.4         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00243    |\n",
            "|    reward               | -0.03790961 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 7.74        |\n",
            "-----------------------------------------\n",
            "day: 4875, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 170775.66\n",
            "total_reward: -829224.34\n",
            "total_cost: 853122.22\n",
            "total_trades: 8498\n",
            "Sharpe: -0.300\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 268          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003630823  |\n",
            "|    clip_fraction        | 0.0338       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 0.0117       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.62         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00418     |\n",
            "|    reward               | -0.008276129 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 4.78         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2020-03-02 to  2020-04-01\n",
            "PPO Sharpe Ratio:  -0.5393740150297556\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_550_1\n",
            "======DDPG Validation from:  2020-03-02 to  2020-04-01\n",
            "======Best Model Retraining from:  2000-01-01 to  2020-04-01\n",
            "======Trading from:  2020-04-01 to  2020-07-13\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2020-06-10\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_616_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 275        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | -0.339     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 4.83       |\n",
            "|    reward             | -2.1811087 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.95       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 277       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 2.21      |\n",
            "|    reward             | 1.0700672 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 1.43      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 277        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -12.1      |\n",
            "|    reward             | 0.17894761 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 34.9       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 277         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.81       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 7.84        |\n",
            "|    reward             | -0.04950882 |\n",
            "|    std                | 0.987       |\n",
            "|    value_loss         | 6.63        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 277       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.81     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 2.75      |\n",
            "|    reward             | 2.3185937 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 18.8      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 255      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.83    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.56     |\n",
            "|    reward             | 1.108    |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.92     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 238        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 2.7        |\n",
            "|    reward             | -3.5218027 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.65       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 228        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 22.1       |\n",
            "|    reward             | -3.0938125 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 56.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 220       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.86     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 17.1      |\n",
            "|    reward             | 5.5174065 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 46.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 220        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -6.13      |\n",
            "|    reward             | -1.7582383 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.69       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 224       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.84     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -6.26     |\n",
            "|    reward             | 1.2041982 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 6.05      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.85    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 3.52     |\n",
            "|    reward             | 4.421698 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 6.91     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 231       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.85     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -0.575    |\n",
            "|    reward             | 4.715543  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 19.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 234       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.85     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -1.6      |\n",
            "|    reward             | -6.819293 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.77      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 236      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.84    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -11.9    |\n",
            "|    reward             | -6.20325 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 24.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 232       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.84     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 0.999     |\n",
            "|    reward             | -2.386793 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 13        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 227        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -19.4      |\n",
            "|    reward             | 0.18270703 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 60.4       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.85    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -5.3     |\n",
            "|    reward             | 5.017922 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 6.6      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 220       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.85     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -39.1     |\n",
            "|    reward             | -7.044293 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 314       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 220        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 45         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.88      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 4.5        |\n",
            "|    reward             | -2.3975618 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.3        |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2020-06-10 to  2020-07-13\n",
            "A2C Sharpe Ratio:  0.25163200843491706\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_616_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 358           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 5             |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | -0.0038570045 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 292         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004917804 |\n",
            "|    clip_fraction        | 0.0324      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.00205    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 24.5        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00373    |\n",
            "|    reward               | 0.0317521   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 48.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 265          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046363077 |\n",
            "|    clip_fraction        | 0.0356       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.00112      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 24.2         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00495     |\n",
            "|    reward               | 0.0048924233 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 51.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 277          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051070116 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | -0.00711     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 8.33         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -0.749252    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 17.7         |\n",
            "------------------------------------------\n",
            "day: 4941, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 310561.06\n",
            "total_reward: -689438.94\n",
            "total_cost: 994329.85\n",
            "total_trades: 8940\n",
            "Sharpe: -0.122\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 265          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049641724 |\n",
            "|    clip_fraction        | 0.0545       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.00173      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.97         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00457     |\n",
            "|    reward               | -0.5892435   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.82         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2020-06-10 to  2020-07-13\n",
            "PPO Sharpe Ratio:  0.47034073779935004\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_616_1\n",
            "======DDPG Validation from:  2020-06-10 to  2020-07-13\n",
            "======Best Model Retraining from:  2000-01-01 to  2020-07-13\n",
            "======Trading from:  2020-07-13 to  2020-10-19\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2020-09-17\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_682_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 174        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | 0.129      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 5.07       |\n",
            "|    reward             | -1.6173812 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 2.84       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 2.37      |\n",
            "|    reward             | 0.8490579 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 0.832     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 192         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | -16.4       |\n",
            "|    reward             | -0.06875439 |\n",
            "|    std                | 0.991       |\n",
            "|    value_loss         | 32.4        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 208         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 6.73        |\n",
            "|    reward             | -0.18071407 |\n",
            "|    std                | 0.99        |\n",
            "|    value_loss         | 7.3         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 220       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | 0.00346   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 2.99      |\n",
            "|    reward             | 1.5920556 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 17.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 228       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0.771    |\n",
            "|    reward             | 1.0126603 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 0.709     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 234       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | -0.179    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.03      |\n",
            "|    reward             | -2.927403 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 1.89      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 236        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 15.9       |\n",
            "|    reward             | -2.6710384 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 47         |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.82    |\n",
            "|    explained_variance | -0.078   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 13.4     |\n",
            "|    reward             | 4.976481 |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 35.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 222       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | 0.0234    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 0.686     |\n",
            "|    reward             | 0.8278376 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 0.12      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 216         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -4.9        |\n",
            "|    reward             | -0.54057366 |\n",
            "|    std                | 0.995       |\n",
            "|    value_loss         | 7.05        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.82    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -10      |\n",
            "|    reward             | 0.7304   |\n",
            "|    std                | 0.991    |\n",
            "|    value_loss         | 10.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 214       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.81     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 11.8      |\n",
            "|    reward             | 0.6669478 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 40.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 217        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.81      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 17.7       |\n",
            "|    reward             | -1.0923125 |\n",
            "|    std                | 0.987      |\n",
            "|    value_loss         | 67.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 221        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.8       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 1.81       |\n",
            "|    reward             | -4.4035664 |\n",
            "|    std                | 0.981      |\n",
            "|    value_loss         | 6.59       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 223         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.81       |\n",
            "|    explained_variance | -0.415      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -14.2       |\n",
            "|    reward             | -0.24981377 |\n",
            "|    std                | 0.987       |\n",
            "|    value_loss         | 27.4        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 226       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.8      |\n",
            "|    explained_variance | 0.00263   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -6.38     |\n",
            "|    reward             | 5.7917404 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 33.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 227         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.8        |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -29.1       |\n",
            "|    reward             | -0.22428963 |\n",
            "|    std                | 0.981       |\n",
            "|    value_loss         | 149         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 225        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.8       |\n",
            "|    explained_variance | -0.423     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 38         |\n",
            "|    reward             | -3.0723522 |\n",
            "|    std                | 0.982      |\n",
            "|    value_loss         | 236        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 221         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.8        |\n",
            "|    explained_variance | -7.02       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -3.72       |\n",
            "|    reward             | -0.30051896 |\n",
            "|    std                | 0.979       |\n",
            "|    value_loss         | 2.49        |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2020-09-17 to  2020-10-19\n",
            "A2C Sharpe Ratio:  0.6327741345457059\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_682_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 254         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 8           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.41284704 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 285          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049731894 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.0425      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 8.15         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    reward               | -0.032134857 |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 12.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 264          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00462289   |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.00116      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.87         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    reward               | 0.0005605327 |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 4.86         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029221564 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.0304      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.44         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    reward               | -0.028002765 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 7.1          |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 269        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 38         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00461601 |\n",
            "|    clip_fraction        | 0.0216     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.84      |\n",
            "|    explained_variance   | -0.104     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.354      |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00273   |\n",
            "|    reward               | -4.388885  |\n",
            "|    std                  | 0.999      |\n",
            "|    value_loss           | 0.77       |\n",
            "----------------------------------------\n",
            "======PPO Validation from:  2020-09-17 to  2020-10-19\n",
            "PPO Sharpe Ratio:  0.3758871727357384\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_682_1\n",
            "======DDPG Validation from:  2020-09-17 to  2020-10-19\n",
            "======Best Model Retraining from:  2000-01-01 to  2020-10-19\n",
            "======Trading from:  2020-10-19 to  2021-01-27\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2020-12-22\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_748_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 274          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.85        |\n",
            "|    explained_variance | 0.0333       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -1.29        |\n",
            "|    reward             | -0.018570933 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.521        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 273          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.85        |\n",
            "|    explained_variance | -27.4        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | -0.367       |\n",
            "|    reward             | 0.0019497168 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.0171       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 275           |\n",
            "|    iterations         | 300           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 1500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.87         |\n",
            "|    explained_variance | 0.63          |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 299           |\n",
            "|    policy_loss        | 0.135         |\n",
            "|    reward             | -0.0015025514 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 0.00301       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 276          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.89        |\n",
            "|    explained_variance | -0.018       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.136       |\n",
            "|    reward             | -0.018626666 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 0.0022       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 265         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.88       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.0662      |\n",
            "|    reward             | -0.07219695 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.00413     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.89     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0.291    |\n",
            "|    reward             | 0.3350499 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.0112    |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 227          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.91        |\n",
            "|    explained_variance | -5.3         |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.0625       |\n",
            "|    reward             | 0.0030163089 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00186      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 218          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.0114       |\n",
            "|    reward             | 0.0008835246 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 2.85e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 213         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.96       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 0.00184     |\n",
            "|    reward             | 0.015710287 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 4.25e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 218        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.97      |\n",
            "|    explained_variance | -9.62      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 0.27       |\n",
            "|    reward             | 0.04716312 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0225     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 222         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.98       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.0345      |\n",
            "|    reward             | -0.04884848 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.000769    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 225        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3         |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 0.413      |\n",
            "|    reward             | 0.09549031 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.0242     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 229          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.114        |\n",
            "|    reward             | -0.027275171 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.00175      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 232            |\n",
            "|    iterations         | 1400           |\n",
            "|    time_elapsed       | 30             |\n",
            "|    total_timesteps    | 7000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.03          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1399           |\n",
            "|    policy_loss        | -0.0097        |\n",
            "|    reward             | -0.00014478808 |\n",
            "|    std                | 1.1            |\n",
            "|    value_loss         | 9.91e-06       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 230            |\n",
            "|    iterations         | 1500           |\n",
            "|    time_elapsed       | 32             |\n",
            "|    total_timesteps    | 7500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.06          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1499           |\n",
            "|    policy_loss        | -0.000836      |\n",
            "|    reward             | -8.8565845e-05 |\n",
            "|    std                | 1.12           |\n",
            "|    value_loss         | 9.19e-08       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 225          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.11        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -0.00351     |\n",
            "|    reward             | 0.0001500696 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 2.13e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 222          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.13        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.0641       |\n",
            "|    reward             | -0.014113944 |\n",
            "|    std                | 1.16         |\n",
            "|    value_loss         | 0.000529     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 218        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.16      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -3.84      |\n",
            "|    reward             | 0.03517078 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 1.39       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 216         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 43          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.15       |\n",
            "|    explained_variance | -0.146      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -7.35       |\n",
            "|    reward             | 0.039121266 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 4.57        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 219         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.17       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 0.00147     |\n",
            "|    reward             | -0.54394925 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 3.28e-07    |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2020-12-22 to  2021-01-27\n",
            "A2C Sharpe Ratio:  -0.013657400219203858\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_748_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 358        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 5          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -0.5589657 |\n",
            "-----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 278          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042173183 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.042       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.75         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    reward               | 0.0          |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 264          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003148025  |\n",
            "|    clip_fraction        | 0.0289       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.00788     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.16         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    reward               | -0.030734431 |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 5.49         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 276         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004095814 |\n",
            "|    clip_fraction        | 0.0229      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | -0.0123     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.39        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00303    |\n",
            "|    reward               | -0.0336779  |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 5.78        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 259          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047299257 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.000101    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.735        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    reward               | 0.3799272    |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 1.99         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2020-12-22 to  2021-01-27\n",
            "PPO Sharpe Ratio:  -0.02759258864647507\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_748_1\n",
            "======DDPG Validation from:  2020-12-22 to  2021-01-27\n",
            "======Best Model Retraining from:  2000-01-01 to  2021-01-27\n",
            "======Trading from:  2021-01-27 to  2021-05-06\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2021-04-01\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_814_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 272          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.392       |\n",
            "|    reward             | 0.0007747108 |\n",
            "|    std                | 0.993        |\n",
            "|    value_loss         | 0.052        |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 274      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.82    |\n",
            "|    explained_variance | 0.155    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.452   |\n",
            "|    reward             | 1.23859  |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 0.0513   |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 273         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | -4.11       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | 0.0768      |\n",
            "|    reward             | 0.027846547 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 0.0788      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 246         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 2.12        |\n",
            "|    reward             | -0.15707485 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 0.89        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 226       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | -0.365    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 0.336     |\n",
            "|    reward             | -0.541915 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 0.306     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 215         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | -0.959      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -1.27       |\n",
            "|    reward             | 0.016241804 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 0.422       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 206        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -0.414     |\n",
            "|    reward             | 0.23438472 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 0.0408     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 207        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | 0.202      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 0.211      |\n",
            "|    reward             | 0.11659434 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 0.0757     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 212        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 0.0253     |\n",
            "|    reward             | 0.13044147 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 0.00319    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 217         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.84       |\n",
            "|    explained_variance | -6.84       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -1.38       |\n",
            "|    reward             | 0.112157255 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.304       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 221           |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.84         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | 0.0108        |\n",
            "|    reward             | 0.00022396573 |\n",
            "|    std                | 1             |\n",
            "|    value_loss         | 3.43e-05      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 225        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 0.529      |\n",
            "|    reward             | -0.1836288 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.039      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 228        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 19.4       |\n",
            "|    reward             | 0.15910937 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 53.5       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.85    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 70.4     |\n",
            "|    reward             | 9.0944   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 692      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 219       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.86     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 1.81      |\n",
            "|    reward             | 4.2647266 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 15.8      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.87    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -22.7    |\n",
            "|    reward             | 3.854672 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 87.3     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 212       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.86     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 6.18      |\n",
            "|    reward             | 0.0405    |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 16.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 213        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | -0.000308  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 4.2        |\n",
            "|    reward             | -1.7884328 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 100        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.85    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -9.4     |\n",
            "|    reward             | 5.568    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 89       |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 218         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.85       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -14         |\n",
            "|    reward             | -0.61095154 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 56.6        |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-04-01 to  2021-05-06\n",
            "A2C Sharpe Ratio:  0.2120019271111978\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_814_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 333        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 6          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -0.0466435 |\n",
            "-----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 250          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038179515 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.0171      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.69         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    reward               | 0.003713481  |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 263          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035780347 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.00989      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.689        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    reward               | -0.006089414 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.826        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 266          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037934736 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | -0.0114      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.67         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    reward               | -0.07361872  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 9.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 250          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040210416 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 0.00523      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.43         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    reward               | 0.13666473   |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 5.72         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-04-01 to  2021-05-06\n",
            "PPO Sharpe Ratio:  -0.18746333748873234\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_814_1\n",
            "day: 5139, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 310084.38\n",
            "total_reward: -689915.62\n",
            "total_cost: 33760.51\n",
            "total_trades: 5339\n",
            "Sharpe: 0.044\n",
            "=================================\n",
            "======DDPG Validation from:  2021-04-01 to  2021-05-06\n",
            "======Best Model Retraining from:  2000-01-01 to  2021-05-06\n",
            "======Trading from:  2021-05-06 to  2021-08-25\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2021-07-26\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_880_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 231          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.85        |\n",
            "|    explained_variance | -1.39        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.689       |\n",
            "|    reward             | 0.0017694825 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.197        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 199        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.86      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.202      |\n",
            "|    reward             | 0.01776258 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.00628    |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 189            |\n",
            "|    iterations         | 300            |\n",
            "|    time_elapsed       | 7              |\n",
            "|    total_timesteps    | 1500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.88          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 299            |\n",
            "|    policy_loss        | 0.00264        |\n",
            "|    reward             | -1.6571601e-05 |\n",
            "|    std                | 1.02           |\n",
            "|    value_loss         | 5.97e-07       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 184            |\n",
            "|    iterations         | 400            |\n",
            "|    time_elapsed       | 10             |\n",
            "|    total_timesteps    | 2000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.91          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 399            |\n",
            "|    policy_loss        | 0.0269         |\n",
            "|    reward             | -2.7892718e-05 |\n",
            "|    std                | 1.03           |\n",
            "|    value_loss         | 0.000105       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 181           |\n",
            "|    iterations         | 500           |\n",
            "|    time_elapsed       | 13            |\n",
            "|    total_timesteps    | 2500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.95         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 499           |\n",
            "|    policy_loss        | -0.0018       |\n",
            "|    reward             | -0.0006366205 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 5.23e-07      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 191      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3       |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.00122  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 3.12e-07 |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 199          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | -0.464       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.88         |\n",
            "|    reward             | -0.055169526 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.351        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 206         |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.02       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 0.0613      |\n",
            "|    reward             | -0.77324873 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.000275    |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.03    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0106   |\n",
            "|    reward             | 1.103555 |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 2.1e-05  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 217        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.05      |\n",
            "|    explained_variance | -764       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 0.819      |\n",
            "|    reward             | 0.04630348 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.185      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 218       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.06     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.0136    |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 1.45e-05  |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 213         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.09       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 0.00894     |\n",
            "|    reward             | 9.46493e-05 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 7.38e-06    |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.13    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -0.0122  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.16     |\n",
            "|    value_loss         | 1.86e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 206       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.14     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -0.0134   |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 3.52e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.16    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.00757  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.18     |\n",
            "|    value_loss         | 8.68e-06 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 207       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.18     |\n",
            "|    explained_variance | 0.154     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -0.284    |\n",
            "|    reward             | -2.74e-07 |\n",
            "|    std                | 1.19      |\n",
            "|    value_loss         | 0.0442    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.18    |\n",
            "|    explained_variance | -0.445   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -7.95    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.19     |\n",
            "|    value_loss         | 4.65     |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 213          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -6.39        |\n",
            "|    reward             | 0.0008164986 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 5.57         |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.17    |\n",
            "|    explained_variance | -0.0678  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.452    |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.18     |\n",
            "|    value_loss         | 0.498    |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 218          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.18        |\n",
            "|    explained_variance | -0.155       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -4.72        |\n",
            "|    reward             | -0.030373879 |\n",
            "|    std                | 1.19         |\n",
            "|    value_loss         | 2.17         |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-07-26 to  2021-08-25\n",
            "A2C Sharpe Ratio:  0.37987638420122866\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_880_1\n",
            "--------------------------------------\n",
            "| time/              |               |\n",
            "|    fps             | 233           |\n",
            "|    iterations      | 1             |\n",
            "|    time_elapsed    | 8             |\n",
            "|    total_timesteps | 2048          |\n",
            "| train/             |               |\n",
            "|    reward          | -0.0059681153 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 242         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004454612 |\n",
            "|    clip_fraction        | 0.029       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.0181     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.19        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00205    |\n",
            "|    reward               | -0.04476889 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 264          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014941526 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0248      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.39         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000848    |\n",
            "|    reward               | 0.020447819  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 4.04         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 244          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038447296 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.000667     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.78         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0017      |\n",
            "|    reward               | -0.55459726  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 14.1         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 251         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005710911 |\n",
            "|    clip_fraction        | 0.0556      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | -0.0135     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.15        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00444    |\n",
            "|    reward               | -0.09251531 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.62        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-07-26 to  2021-08-25\n",
            "PPO Sharpe Ratio:  0.628564541653191\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_880_1\n",
            "day: 5205, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 343292.46\n",
            "total_reward: -656707.54\n",
            "total_cost: 689675.15\n",
            "total_trades: 1575\n",
            "Sharpe: -0.197\n",
            "=================================\n",
            "======DDPG Validation from:  2021-07-26 to  2021-08-25\n",
            "======Best Model Retraining from:  2000-01-01 to  2021-08-25\n",
            "======Trading from:  2021-08-25 to  2021-12-01\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2021-10-28\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_946_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 170          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0139      |\n",
            "|    reward             | -0.036851235 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.00185      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 177         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.89       |\n",
            "|    explained_variance | -2.1        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.217       |\n",
            "|    reward             | 0.054988325 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0288      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 201          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.88        |\n",
            "|    explained_variance | 0.128        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 1.29         |\n",
            "|    reward             | -0.008951895 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.27         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 215         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.88       |\n",
            "|    explained_variance | 0.292       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 4.46        |\n",
            "|    reward             | -0.21531068 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 3.99        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 224         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.88       |\n",
            "|    explained_variance | -3e-05      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -1.82       |\n",
            "|    reward             | -0.68740875 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.57        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 230        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.88      |\n",
            "|    explained_variance | -0.106     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -1.94      |\n",
            "|    reward             | 0.23976572 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.642      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 235         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.89       |\n",
            "|    explained_variance | 0.349       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.572       |\n",
            "|    reward             | -0.32688588 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0444      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 228        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.91      |\n",
            "|    explained_variance | -0.0195    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 2.32       |\n",
            "|    reward             | -0.2776616 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.581      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 219        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.92      |\n",
            "|    explained_variance | -0.33      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 1.28       |\n",
            "|    reward             | 0.55174065 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.351      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 211        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.92      |\n",
            "|    explained_variance | -7.53      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -0.343     |\n",
            "|    reward             | 0.14089487 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.209      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 206       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.94     |\n",
            "|    explained_variance | -0.0909   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -39.2     |\n",
            "|    reward             | 0.8440634 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 188       |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 207           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.94         |\n",
            "|    explained_variance | 2.38e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | -3.85         |\n",
            "|    reward             | -0.0073557086 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 1.51          |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 211        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.94      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -16        |\n",
            "|    reward             | -7.3788633 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 51         |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.92    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 57.6     |\n",
            "|    reward             | 8.449994 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 265      |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 217         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.93       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -6.73       |\n",
            "|    reward             | 0.044171494 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 20.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 220        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.93      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -3.08      |\n",
            "|    reward             | -10.428419 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 61.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 221       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.94     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 12.3      |\n",
            "|    reward             | -1.748039 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 90.1      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.94    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 26.1     |\n",
            "|    reward             | 18.1561  |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 443      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 215       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.93     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 9.81      |\n",
            "|    reward             | 2.1846187 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 50.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.93    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -3.1     |\n",
            "|    reward             | 19.6037  |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 139      |\n",
            "------------------------------------\n",
            "======A2C Validation from:  2021-10-28 to  2021-12-01\n",
            "A2C Sharpe Ratio:  1.0029002129747686\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_946_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 291         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 7           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.29615465 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 299          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056902072 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.0223      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 6.17         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00325     |\n",
            "|    reward               | -0.010722634 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 12.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 255         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004076711 |\n",
            "|    clip_fraction        | 0.0298      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.00172    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.714       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00336    |\n",
            "|    reward               | 0.008426563 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.41        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 263          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032772305 |\n",
            "|    clip_fraction        | 0.00781      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.00316      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 6.07         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -9.14e-05    |\n",
            "|    reward               | -0.020623455 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 15.3         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 265            |\n",
            "|    iterations           | 5              |\n",
            "|    time_elapsed         | 38             |\n",
            "|    total_timesteps      | 10240          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.004860185    |\n",
            "|    clip_fraction        | 0.03           |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.85          |\n",
            "|    explained_variance   | 0.00836        |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 2.42           |\n",
            "|    n_updates            | 40             |\n",
            "|    policy_gradient_loss | -0.00456       |\n",
            "|    reward               | -0.00012971504 |\n",
            "|    std                  | 1              |\n",
            "|    value_loss           | 5.11           |\n",
            "--------------------------------------------\n",
            "======PPO Validation from:  2021-10-28 to  2021-12-01\n",
            "PPO Sharpe Ratio:  0.4286523695698182\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_946_1\n",
            "day: 5271, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 362576.25\n",
            "total_reward: -637423.75\n",
            "total_cost: 80764.15\n",
            "total_trades: 6543\n",
            "Sharpe: 0.041\n",
            "=================================\n",
            "======DDPG Validation from:  2021-10-28 to  2021-12-01\n",
            "======Best Model Retraining from:  2000-01-01 to  2021-12-01\n",
            "======Trading from:  2021-12-01 to  2022-03-08\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2022-02-03\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1012_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 272          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | -0.0746      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -3.57        |\n",
            "|    reward             | 0.0007690458 |\n",
            "|    std                | 0.991        |\n",
            "|    value_loss         | 1.32         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 272         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -0.652      |\n",
            "|    reward             | 0.026986463 |\n",
            "|    std                | 0.992       |\n",
            "|    value_loss         | 0.0949      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 228          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.937        |\n",
            "|    reward             | -0.007110028 |\n",
            "|    std                | 0.993        |\n",
            "|    value_loss         | 0.0746       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 210         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.84       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 2.46        |\n",
            "|    reward             | -0.19187035 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.39        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 201         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | 0.0916      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.752       |\n",
            "|    reward             | -0.76273286 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 0.419       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 196         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -2.5        |\n",
            "|    reward             | 0.026116082 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.3         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 199       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.87     |\n",
            "|    explained_variance | -0.421    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -0.943    |\n",
            "|    reward             | 0.4091438 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.0732    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 206        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.88      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 0.494      |\n",
            "|    reward             | 0.19152385 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.241      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 212        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.86      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 0.145      |\n",
            "|    reward             | 0.30469325 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0211     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 217        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.87      |\n",
            "|    explained_variance | 0.436      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 0.806      |\n",
            "|    reward             | 0.86204755 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.156      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 221        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.88      |\n",
            "|    explained_variance | -0.0422    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 0.0816     |\n",
            "|    reward             | 0.04114029 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.00807    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 223       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.89     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -0.422    |\n",
            "|    reward             | 0.0459803 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.103     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 218          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.87        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 2.44         |\n",
            "|    reward             | -0.019092549 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.917        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 214         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -1.28       |\n",
            "|    reward             | -0.32301053 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.34        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 211         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | -0.0966     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -3.02       |\n",
            "|    reward             | -0.08814751 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 4.5         |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 208         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.88       |\n",
            "|    explained_variance | 0.125       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -1.15       |\n",
            "|    reward             | -0.42120868 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.348       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 209         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | 0.026       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 1.6         |\n",
            "|    reward             | -0.16652258 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.521       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 212       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.88     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -3.3      |\n",
            "|    reward             | 0.3722277 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.14      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 215         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.88       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -1.73       |\n",
            "|    reward             | -0.39182997 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.5         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 217        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 45         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.87      |\n",
            "|    explained_variance | -0.167     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 2.53       |\n",
            "|    reward             | -0.1959138 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.655      |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-02-03 to  2022-03-08\n",
            "A2C Sharpe Ratio:  -0.10933437574984199\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_1012_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 271         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 7           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.03059623 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 240          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039546234 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00942     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.3          |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | 0.04135293   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 6.43         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 261         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007705695 |\n",
            "|    clip_fraction        | 0.0864      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | -0.181      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.109       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00722    |\n",
            "|    reward               | -0.04830735 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.274       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 251         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007955352 |\n",
            "|    clip_fraction        | 0.0764      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | -0.0114     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.47        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00501    |\n",
            "|    reward               | -1.4628295  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 249          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 41           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031817697 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0155      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.23         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    reward               | 0.15264113   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 8.58         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2022-02-03 to  2022-03-08\n",
            "PPO Sharpe Ratio:  -0.07385789539228556\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1012_1\n",
            "day: 5337, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 106638.22\n",
            "total_reward: -893361.78\n",
            "total_cost: 40918.82\n",
            "total_trades: 7732\n",
            "Sharpe: 0.304\n",
            "=================================\n",
            "======DDPG Validation from:  2022-02-03 to  2022-03-08\n",
            "======Best Model Retraining from:  2000-01-01 to  2022-03-08\n",
            "======Trading from:  2022-03-08 to  2022-06-16\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2022-05-13\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1078_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.86      |\n",
            "|    explained_variance | -0.305     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -3.24      |\n",
            "|    reward             | -6.2550836 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.86     |\n",
            "|    explained_variance | 0.0765    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 13.4      |\n",
            "|    reward             | 4.0612726 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 43.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 268        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | -0.000455  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -64.7      |\n",
            "|    reward             | 0.29847595 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 674        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 244        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | 0.246      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 29.3       |\n",
            "|    reward             | -0.3568963 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 135        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 224       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | 0.0301    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 17.3      |\n",
            "|    reward             | 6.9160438 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 211       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 213       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | -0.0925   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 3.86      |\n",
            "|    reward             | 3.5076659 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 8.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 205        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | -0.0116    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 6.4        |\n",
            "|    reward             | -10.112167 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 23.6       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 205      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.83    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 39       |\n",
            "|    reward             | -8.85327 |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 491      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 211       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 47.6      |\n",
            "|    reward             | 16.199572 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 401       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.83     |\n",
            "|    explained_variance | -72.4     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 1.63      |\n",
            "|    reward             | 0.5354586 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 1.72      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 220      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.83    |\n",
            "|    explained_variance | -0.0273  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -21.3    |\n",
            "|    reward             | 3.2912   |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 62.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 223       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.81     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -5.25     |\n",
            "|    reward             | 1.0791992 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 4.51      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 226       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.8      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.503     |\n",
            "|    reward             | 1.3902613 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 0.994     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 221         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 7.62        |\n",
            "|    reward             | -0.06732266 |\n",
            "|    std                | 0.992       |\n",
            "|    value_loss         | 7.49        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 217       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.84     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 10        |\n",
            "|    reward             | -7.966545 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 16.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 213      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.83    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -4.9     |\n",
            "|    reward             | 2.2572   |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 10.4     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 210        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 5.66       |\n",
            "|    reward             | 0.46991485 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 8.24       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 211         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 8.94        |\n",
            "|    reward             | -0.53426486 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 53.4        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.83    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 32.2     |\n",
            "|    reward             | -0.24255 |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 92.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 216        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.84      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -9.13      |\n",
            "|    reward             | -5.4304852 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 18         |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-05-13 to  2022-06-16\n",
            "A2C Sharpe Ratio:  0.24906514349323525\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_1078_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 320         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 6           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.33822653 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 244          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036329592 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.00163      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.63         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    reward               | 0.026530527  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 8.65         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007868773 |\n",
            "|    clip_fraction        | 0.0553      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.0237     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.53        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00496    |\n",
            "|    reward               | 0.30715194  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.67        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 259           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 31            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.003202253   |\n",
            "|    clip_fraction        | 0.0106        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | -0.0113       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 2.57          |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.00193      |\n",
            "|    reward               | 3.1551157e-05 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 6.15          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 247           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 41            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0047944197  |\n",
            "|    clip_fraction        | 0.0216        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | -0.0151       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.506         |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00339      |\n",
            "|    reward               | -0.0015947026 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.05          |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2022-05-13 to  2022-06-16\n",
            "PPO Sharpe Ratio:  0.26078859941161653\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1078_1\n",
            "day: 5403, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 50745.47\n",
            "total_reward: -949254.53\n",
            "total_cost: 37882.32\n",
            "total_trades: 3000\n",
            "Sharpe: 0.089\n",
            "=================================\n",
            "======DDPG Validation from:  2022-05-13 to  2022-06-16\n",
            "======Best Model Retraining from:  2000-01-01 to  2022-06-16\n",
            "======Trading from:  2022-06-16 to  2022-09-27\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2022-08-24\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1144_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 235        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.81      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -0.284     |\n",
            "|    reward             | -0.2868247 |\n",
            "|    std                | 0.985      |\n",
            "|    value_loss         | 0.0231     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 250         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | -0.7        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -0.0399     |\n",
            "|    reward             | 0.008173904 |\n",
            "|    std                | 0.99        |\n",
            "|    value_loss         | 0.00167     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 257           |\n",
            "|    iterations         | 300           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 1500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.81         |\n",
            "|    explained_variance | 0.289         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 299           |\n",
            "|    policy_loss        | -9.79         |\n",
            "|    reward             | -0.0009373651 |\n",
            "|    std                | 0.985         |\n",
            "|    value_loss         | 14.9          |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 260          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | -0.212       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | 6.85         |\n",
            "|    reward             | -0.121449456 |\n",
            "|    std                | 0.989        |\n",
            "|    value_loss         | 6.91         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 262         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.81       |\n",
            "|    explained_variance | 0.0413      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -9.7        |\n",
            "|    reward             | -0.09138201 |\n",
            "|    std                | 0.986       |\n",
            "|    value_loss         | 20.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 255       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | 0.182     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 2.18      |\n",
            "|    reward             | 0.4865698 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 0.609     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 238       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.8      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.15      |\n",
            "|    reward             | -1.232629 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 0.359     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 227        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.8       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 3.91       |\n",
            "|    reward             | -0.7734531 |\n",
            "|    std                | 0.979      |\n",
            "|    value_loss         | 3.62       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 218       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.8      |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 3.88      |\n",
            "|    reward             | 1.3793516 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.06      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 212         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.78       |\n",
            "|    explained_variance | -1.2e+03    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.534      |\n",
            "|    reward             | 0.016200073 |\n",
            "|    std                | 0.971       |\n",
            "|    value_loss         | 0.188       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.78    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -5.69    |\n",
            "|    reward             | -2.574   |\n",
            "|    std                | 0.97     |\n",
            "|    value_loss         | 8.94     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 220        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.8       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -0.306     |\n",
            "|    reward             | -2.3206508 |\n",
            "|    std                | 0.983      |\n",
            "|    value_loss         | 0.407      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 223       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.8      |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -10.1     |\n",
            "|    reward             | 1.0880947 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 21.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 226        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.79      |\n",
            "|    explained_variance | -0.965     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -13        |\n",
            "|    reward             | -3.2891402 |\n",
            "|    std                | 0.977      |\n",
            "|    value_loss         | 28.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 229        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.8       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -1.74      |\n",
            "|    reward             | -2.5625703 |\n",
            "|    std                | 0.983      |\n",
            "|    value_loss         | 8.14       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 226        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.81      |\n",
            "|    explained_variance | -0.0289    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -16.3      |\n",
            "|    reward             | -1.6627977 |\n",
            "|    std                | 0.987      |\n",
            "|    value_loss         | 38.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 222        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.81      |\n",
            "|    explained_variance | -0.0612    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -1.17      |\n",
            "|    reward             | -2.9606164 |\n",
            "|    std                | 0.987      |\n",
            "|    value_loss         | 2.84       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 218       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.79     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -54.9     |\n",
            "|    reward             | 3.9472468 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 294       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 215         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -25.7       |\n",
            "|    reward             | -0.48119688 |\n",
            "|    std                | 0.979       |\n",
            "|    value_loss         | 98.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 214        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.79      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 32.8       |\n",
            "|    reward             | -0.9110063 |\n",
            "|    std                | 0.976      |\n",
            "|    value_loss         | 209        |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-08-24 to  2022-09-27\n",
            "A2C Sharpe Ratio:  0.15458498387024935\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_1144_1\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 348          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 5            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | -0.013719287 |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 285          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041820547 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.00531     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 19.2         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    reward               | -0.029377421 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 41.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030893376 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00281     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.9          |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00418     |\n",
            "|    reward               | 0.32492194   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 11.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 270          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060771736 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | -0.0229      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 11.2         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    reward               | -0.031421326 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 257          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004838302  |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00641     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.385        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0037      |\n",
            "|    reward               | -0.029187353 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.838        |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2022-08-24 to  2022-09-27\n",
            "PPO Sharpe Ratio:  0.3304875484587958\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1144_1\n",
            "day: 5469, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 132769.91\n",
            "total_reward: -867230.09\n",
            "total_cost: 34494.01\n",
            "total_trades: 5555\n",
            "Sharpe: 0.327\n",
            "=================================\n",
            "======DDPG Validation from:  2022-08-24 to  2022-09-27\n",
            "======Best Model Retraining from:  2000-01-01 to  2022-09-27\n",
            "======Trading from:  2022-09-27 to  2022-12-30\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2022-11-29\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1210_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 201           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 2             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.84         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0222       |\n",
            "|    reward             | 0.00022195501 |\n",
            "|    std                | 1             |\n",
            "|    value_loss         | 9.98e-05      |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.86     |\n",
            "|    explained_variance | -0.196    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.66      |\n",
            "|    reward             | 0.3040031 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.29      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.88     |\n",
            "|    explained_variance | -1.27     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -0.674    |\n",
            "|    reward             | 0.0421381 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.0682    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 175         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | -0.0819     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -0.444      |\n",
            "|    reward             | -0.06574174 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.073       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 178         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.9        |\n",
            "|    explained_variance | -49.2       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.0051      |\n",
            "|    reward             | -7.2912e-06 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.000111    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 188       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.9      |\n",
            "|    explained_variance | -0.778    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 1.5       |\n",
            "|    reward             | 0.5550181 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.636     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 197        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.9       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 0.583      |\n",
            "|    reward             | -1.4787596 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.515      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 204        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.89      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 12         |\n",
            "|    reward             | -1.1054895 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 210       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.9      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 6.4       |\n",
            "|    reward             | 2.2877626 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 6.26      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 214       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.9      |\n",
            "|    explained_variance | 0.692     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 0.627     |\n",
            "|    reward             | 1.2679455 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.15      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 211        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.9       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -0.189     |\n",
            "|    reward             | 0.76904726 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.05       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 206         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.9        |\n",
            "|    explained_variance | 0.00752     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.0582     |\n",
            "|    reward             | -0.22767393 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 5.65        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 203        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.91      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 25.2       |\n",
            "|    reward             | -2.9120913 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 98.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 200       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.91     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -15.7     |\n",
            "|    reward             | 4.5038943 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 30        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 201       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.9      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 7.01      |\n",
            "|    reward             | 3.7076151 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 16.2      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.9     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 9.72     |\n",
            "|    reward             | 11.31292 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 35.7     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 207       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.9      |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -8.84     |\n",
            "|    reward             | -2.501839 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 21.4      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.91    |\n",
            "|    explained_variance | -0.00577 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 15.2     |\n",
            "|    reward             | 4.081964 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 60.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 212       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.92     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -24.9     |\n",
            "|    reward             | 13.144091 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 55.5      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.92    |\n",
            "|    explained_variance | -0.00605 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.846    |\n",
            "|    reward             | 3.844133 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 31.1     |\n",
            "------------------------------------\n",
            "======A2C Validation from:  2022-11-29 to  2022-12-30\n",
            "A2C Sharpe Ratio:  0.18931386790144272\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_1210_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 217        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 9          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -1.2744474 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 243         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005000348 |\n",
            "|    clip_fraction        | 0.0504      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | -0.00442    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 17.1        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00365    |\n",
            "|    reward               | -0.09584012 |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 29.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 252          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069308383 |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.00252     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 27.3         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    reward               | -0.030360578 |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 50.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 235          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048814053 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.0133      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 9.36         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    reward               | 0.0007970578 |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 15.2         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 248        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 41         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00608175 |\n",
            "|    clip_fraction        | 0.0374     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.81      |\n",
            "|    explained_variance   | -0.0462    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 8.11       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00429   |\n",
            "|    reward               | 0.97613406 |\n",
            "|    std                  | 0.98       |\n",
            "|    value_loss           | 14.4       |\n",
            "----------------------------------------\n",
            "======PPO Validation from:  2022-11-29 to  2022-12-30\n",
            "PPO Sharpe Ratio:  0.6233470599412096\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1210_1\n",
            "day: 5535, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 662981.59\n",
            "total_reward: -337018.41\n",
            "total_cost: 32125.15\n",
            "total_trades: 5609\n",
            "Sharpe: 0.147\n",
            "=================================\n",
            "======DDPG Validation from:  2022-11-29 to  2022-12-30\n",
            "======Best Model Retraining from:  2000-01-01 to  2022-12-30\n",
            "======Trading from:  2022-12-30 to  2023-04-13\n",
            "============================================\n",
            "turbulence_threshold:  15.504289532910217\n",
            "======Model training from:  2000-01-01 to  2023-03-13\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1276_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 265        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | -0.25      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -2.98      |\n",
            "|    reward             | -1.5818423 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 2.35       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 265         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.81       |\n",
            "|    explained_variance | -0.179      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -2.72       |\n",
            "|    reward             | 0.013874882 |\n",
            "|    std                | 0.987       |\n",
            "|    value_loss         | 0.825       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 267          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.81        |\n",
            "|    explained_variance | -0.0286      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -9.34        |\n",
            "|    reward             | -0.079603806 |\n",
            "|    std                | 0.986        |\n",
            "|    value_loss         | 18.3         |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 268          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.81        |\n",
            "|    explained_variance | -0.86        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | 4.21         |\n",
            "|    reward             | -0.038696423 |\n",
            "|    std                | 0.987        |\n",
            "|    value_loss         | 3.16         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 252       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | 0.0145    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 4.91      |\n",
            "|    reward             | 1.1574374 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 4.97      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 234           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.81         |\n",
            "|    explained_variance | 0.162         |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.566         |\n",
            "|    reward             | 0.00015419119 |\n",
            "|    std                | 0.988         |\n",
            "|    value_loss         | 0.185         |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 222       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.82     |\n",
            "|    explained_variance | -0.00627  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 0.725     |\n",
            "|    reward             | -1.056542 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 0.112     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 213        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 18         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.82      |\n",
            "|    explained_variance | 0.2        |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 4.71       |\n",
            "|    reward             | -0.7673703 |\n",
            "|    std                | 0.991      |\n",
            "|    value_loss         | 2.67       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 210        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.83      |\n",
            "|    explained_variance | -0.0251    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 1.76       |\n",
            "|    reward             | 0.87002265 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 0.443      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 215        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | -2.99      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -0.106     |\n",
            "|    reward             | 0.28520304 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0465     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 219        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.87      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 0.062      |\n",
            "|    reward             | 0.22310871 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.181      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.88    |\n",
            "|    explained_variance | -0.195   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 4.59     |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 8.55     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 225        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.88      |\n",
            "|    explained_variance | 0.0567     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 1.41       |\n",
            "|    reward             | -1.0133983 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.365      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.89    |\n",
            "|    explained_variance | -80.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.327   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.0678   |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 224           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.92         |\n",
            "|    explained_variance | -0.0804       |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | 5.79          |\n",
            "|    reward             | -0.0038846247 |\n",
            "|    std                | 1.04          |\n",
            "|    value_loss         | 6.13          |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 219        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.94      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 0.0312     |\n",
            "|    reward             | -0.8479883 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.000145   |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 215            |\n",
            "|    iterations         | 1700           |\n",
            "|    time_elapsed       | 39             |\n",
            "|    total_timesteps    | 8500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.94          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1699           |\n",
            "|    policy_loss        | 0.0422         |\n",
            "|    reward             | -1.5601725e-05 |\n",
            "|    std                | 1.05           |\n",
            "|    value_loss         | 0.000261       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 212          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.000824    |\n",
            "|    reward             | 0.0006800699 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 1.14e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 212          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.96        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0543      |\n",
            "|    reward             | -0.017325656 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.000812     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 215          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3           |\n",
            "|    explained_variance | -11.7        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | 0.0795       |\n",
            "|    reward             | -0.022591177 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.0163       |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2023-03-13 to  2023-04-13\n",
            "A2C Sharpe Ratio:  -0.23553148348277375\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_1276_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 346         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 5           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.05586107 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 256          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002869669  |\n",
            "|    clip_fraction        | 0.0276       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.102       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.93         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    reward               | 0.0081317695 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 7.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 257          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035018339 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00792     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.224        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00495     |\n",
            "|    reward               | -0.16937852  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 264          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056749354 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.0209       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.94         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00427     |\n",
            "|    reward               | 0.21191344   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 5.12         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 246          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 41           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006476217  |\n",
            "|    clip_fraction        | 0.0404       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0086      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.39         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00418     |\n",
            "|    reward               | -0.037083186 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 6.41         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2023-03-13 to  2023-04-13\n",
            "PPO Sharpe Ratio:  -0.10847064988355394\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1276_1\n",
            "day: 5601, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 718245.33\n",
            "total_reward: -281754.67\n",
            "total_cost: 32948.33\n",
            "total_trades: 5674\n",
            "Sharpe: 0.156\n",
            "=================================\n",
            "======DDPG Validation from:  2023-03-13 to  2023-04-13\n",
            "======Best Model Retraining from:  2000-01-01 to  2023-04-13\n",
            "======Trading from:  2023-04-13 to  2023-07-27\n",
            "Ensemble Strategy took:  106.68477139472961  minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "0MN9uyE9qock",
        "outputId": "4117ae9f-750b-4685-ade5-a737747e7adf"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0     88  2018-04-02  2018-05-04        A2C  -0.008736  -0.621087   -0.654422\n",
              "1    154  2018-07-10  2018-08-09        A2C   0.418099  -0.292302    0.138598\n",
              "2    220  2018-10-18  2018-11-20       DDPG  -0.122874  -0.436576         0.0\n",
              "3    286  2019-01-28  2019-02-28        PPO   0.215882   0.411323    0.215882\n",
              "4    352  2019-05-06  2019-06-11        PPO   0.089006   0.135719   -0.663992\n",
              "5    418  2019-08-19  2019-09-20        A2C   0.538997  -0.276332         0.0\n",
              "6    484  2019-11-22  2019-12-26        A2C   0.589593  -0.118862    0.520531\n",
              "7    550  2020-03-02  2020-04-01       DDPG  -0.768441  -0.539374   -0.300297\n",
              "8    616  2020-06-10  2020-07-13        PPO   0.251632   0.470341    0.251632\n",
              "9    682  2020-09-17  2020-10-19        A2C   0.632774   0.375887         0.0\n",
              "10   748  2020-12-22  2021-01-27       DDPG  -0.013657  -0.027593    0.248176\n",
              "11   814  2021-04-01  2021-05-06        A2C   0.212002  -0.187463   -0.154766\n",
              "12   880  2021-07-26  2021-08-25        PPO   0.379876   0.628565         0.0\n",
              "13   946  2021-10-28  2021-12-01        A2C     1.0029   0.428652   -0.249472\n",
              "14  1012  2022-02-03  2022-03-08       DDPG  -0.109334  -0.073858         0.0\n",
              "15  1078  2022-05-13  2022-06-16        PPO   0.249065   0.260789    0.249756\n",
              "16  1144  2022-08-24  2022-09-27        PPO   0.154585   0.330488    0.154585\n",
              "17  1210  2022-11-29  2022-12-30        PPO   0.189314   0.623347    0.525309\n",
              "18  1276  2023-03-13  2023-04-13        PPO  -0.235531  -0.108471   -0.121307"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e078605-5226-4736-9c32-39bf966dfc61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88</td>\n",
              "      <td>2018-04-02</td>\n",
              "      <td>2018-05-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.008736</td>\n",
              "      <td>-0.621087</td>\n",
              "      <td>-0.654422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>2018-07-10</td>\n",
              "      <td>2018-08-09</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.418099</td>\n",
              "      <td>-0.292302</td>\n",
              "      <td>0.138598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>2018-10-18</td>\n",
              "      <td>2018-11-20</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.122874</td>\n",
              "      <td>-0.436576</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>286</td>\n",
              "      <td>2019-01-28</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.215882</td>\n",
              "      <td>0.411323</td>\n",
              "      <td>0.215882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352</td>\n",
              "      <td>2019-05-06</td>\n",
              "      <td>2019-06-11</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.089006</td>\n",
              "      <td>0.135719</td>\n",
              "      <td>-0.663992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>418</td>\n",
              "      <td>2019-08-19</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.538997</td>\n",
              "      <td>-0.276332</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>484</td>\n",
              "      <td>2019-11-22</td>\n",
              "      <td>2019-12-26</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.589593</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>0.520531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>550</td>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>2020-04-01</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.768441</td>\n",
              "      <td>-0.539374</td>\n",
              "      <td>-0.300297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>616</td>\n",
              "      <td>2020-06-10</td>\n",
              "      <td>2020-07-13</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.251632</td>\n",
              "      <td>0.470341</td>\n",
              "      <td>0.251632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>682</td>\n",
              "      <td>2020-09-17</td>\n",
              "      <td>2020-10-19</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.632774</td>\n",
              "      <td>0.375887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>748</td>\n",
              "      <td>2020-12-22</td>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.013657</td>\n",
              "      <td>-0.027593</td>\n",
              "      <td>0.248176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>814</td>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>2021-05-06</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.212002</td>\n",
              "      <td>-0.187463</td>\n",
              "      <td>-0.154766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>880</td>\n",
              "      <td>2021-07-26</td>\n",
              "      <td>2021-08-25</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.379876</td>\n",
              "      <td>0.628565</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>946</td>\n",
              "      <td>2021-10-28</td>\n",
              "      <td>2021-12-01</td>\n",
              "      <td>A2C</td>\n",
              "      <td>1.0029</td>\n",
              "      <td>0.428652</td>\n",
              "      <td>-0.249472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1012</td>\n",
              "      <td>2022-02-03</td>\n",
              "      <td>2022-03-08</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.109334</td>\n",
              "      <td>-0.073858</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1078</td>\n",
              "      <td>2022-05-13</td>\n",
              "      <td>2022-06-16</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.249065</td>\n",
              "      <td>0.260789</td>\n",
              "      <td>0.249756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1144</td>\n",
              "      <td>2022-08-24</td>\n",
              "      <td>2022-09-27</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.154585</td>\n",
              "      <td>0.330488</td>\n",
              "      <td>0.154585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1210</td>\n",
              "      <td>2022-11-29</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.189314</td>\n",
              "      <td>0.623347</td>\n",
              "      <td>0.525309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1276</td>\n",
              "      <td>2023-03-13</td>\n",
              "      <td>2023-04-13</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.235531</td>\n",
              "      <td>-0.108471</td>\n",
              "      <td>-0.121307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e078605-5226-4736-9c32-39bf966dfc61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e078605-5226-4736-9c32-39bf966dfc61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e078605-5226-4736-9c32-39bf966dfc61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbbab7d8-6773-4902-b365-0425cd8eeda1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbbab7d8-6773-4902-b365-0425cd8eeda1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbbab7d8-6773-4902-b365-0425cd8eeda1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ],
      "metadata": {
        "id": "DnBDV2Hjqses"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = pd.concat([df_account_value,temp],ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGWZoI9Mqvkd",
        "outputId": "c93e2b67-ce45-4fb0-a8b6-0023ff00c3bc"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio:  -0.02353412126950952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_account_value.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FOhA6kO-qyW7",
        "outputId": "9e80623e-3719-4946-f1cc-6b22aaddfb67"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    account_value        date  daily_return    datadate\n",
              "0  1000000.000000  2018-05-04           NaN  2018-05-04\n",
              "1  1000000.000000  2018-05-07      0.000000  2018-05-07\n",
              "2  1000000.000000  2018-05-08      0.000000  2018-05-08\n",
              "3  1000000.000000  2018-05-09      0.000000  2018-05-09\n",
              "4   999998.667852  2018-05-10     -0.000001  2018-05-10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6b50ecb-687c-4f49-91fa-75b45d0431fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2018-05-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2018-05-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2018-05-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2018-05-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2018-05-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2018-05-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2018-05-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>999998.667852</td>\n",
              "      <td>2018-05-10</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>2018-05-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6b50ecb-687c-4f49-91fa-75b45d0431fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6b50ecb-687c-4f49-91fa-75b45d0431fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6b50ecb-687c-4f49-91fa-75b45d0431fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfe23d66-f768-4604-900e-5623f3a6f660\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfe23d66-f768-4604-900e-5623f3a6f660')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfe23d66-f768-4604-900e-5623f3a6f660 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "hzo0p3WbqzXi",
        "outputId": "1590bcc5-af2c-44e8-aff9-45f34097c1ed"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A63X2lWMq1Ty",
        "outputId": "aabe35a1-e4e4-43d0-868f-14aa5be5d444"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return         -0.464331\n",
            "Cumulative returns    -0.955235\n",
            "Annual volatility      0.491095\n",
            "Sharpe ratio          -0.023534\n",
            "Calmar ratio          -0.473211\n",
            "Stability              0.640613\n",
            "Max drawdown          -0.981235\n",
            "Omega ratio            0.989195\n",
            "Sortino ratio         -0.024829\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.160234\n",
            "Daily value at risk   -0.061918\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFsX55F1q3cB",
        "outputId": "ba14f29d-bcdf-4aad-af76-ec377052a991"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Baseline Stats===========\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (1314, 8)\n",
            "Annual return          0.075362\n",
            "Cumulative returns     0.460610\n",
            "Annual volatility      0.210795\n",
            "Sharpe ratio           0.450952\n",
            "Calmar ratio           0.203207\n",
            "Stability              0.681708\n",
            "Max drawdown          -0.370862\n",
            "Omega ratio            1.094825\n",
            "Sortino ratio          0.625152\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.930203\n",
            "Daily value at risk   -0.026180\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "df_account_value.to_csv('df_account_value.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_gTHpEVq48q",
        "outputId": "38ccf44b-bb64-41c1-dc03-35dc84149fe5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_dji:              date           dji\n",
            "0     2018-05-04  1.000000e+06\n",
            "1     2018-05-07  1.003908e+06\n",
            "2     2018-05-08  1.004027e+06\n",
            "3     2018-05-09  1.011542e+06\n",
            "4     2018-05-10  1.019661e+06\n",
            "...          ...           ...\n",
            "1249  2023-07-20  1.393465e+06\n",
            "1250  2023-07-21  1.396203e+06\n",
            "1251  2023-07-24  1.382002e+06\n",
            "1252  2023-07-25  1.372565e+06\n",
            "1253  2023-07-26  1.394174e+06\n",
            "\n",
            "[1254 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2018-05-04  1.000000e+06\n",
            "2018-05-07  1.003908e+06\n",
            "2018-05-08  1.004027e+06\n",
            "2018-05-09  1.011542e+06\n",
            "2018-05-10  1.019661e+06\n",
            "...                  ...\n",
            "2023-07-20  1.393465e+06\n",
            "2023-07-21  1.396203e+06\n",
            "2023-07-24  1.382002e+06\n",
            "2023-07-25  1.372565e+06\n",
            "2023-07-26  1.394174e+06\n",
            "\n",
            "[1254 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value,\n",
        "#               baseline_ticker = '^DJI',\n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'dji']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6UszABhZq7qq",
        "outputId": "e9225814-29e2-4b00-f244-5ba6385561ff"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
            "df_trade_date:          datadate\n",
            "0     2018-04-02\n",
            "1     2018-04-03\n",
            "2     2018-04-04\n",
            "3     2018-04-05\n",
            "4     2018-04-06\n",
            "...          ...\n",
            "1308  2023-09-13\n",
            "1309  2023-09-14\n",
            "1310  2023-09-15\n",
            "1311  2023-09-18\n",
            "1312  2023-09-19\n",
            "\n",
            "[1313 rows x 1 columns]\n",
            "df_result_ensemble:                    ensemble\n",
            "date                      \n",
            "2018-05-04  1000000.000000\n",
            "2018-05-07  1000000.000000\n",
            "2018-05-08  1000000.000000\n",
            "2018-05-09  1000000.000000\n",
            "2018-05-10   999998.667852\n",
            "...                    ...\n",
            "2023-07-20    45047.764297\n",
            "2023-07-21    44851.767767\n",
            "2023-07-24    44827.773206\n",
            "2023-07-25    44509.683869\n",
            "2023-07-26    44764.774118\n",
            "\n",
            "[1254 rows x 1 columns]\n",
            "==============Compare to DJIA===========\n",
            "result:                    ensemble           dji\n",
            "date                                    \n",
            "2018-05-04  1000000.000000  1.000000e+06\n",
            "2018-05-07  1000000.000000  1.003908e+06\n",
            "2018-05-08  1000000.000000  1.004027e+06\n",
            "2018-05-09  1000000.000000  1.011542e+06\n",
            "2018-05-10   999998.667852  1.019661e+06\n",
            "...                    ...           ...\n",
            "2023-07-20    45047.764297  1.393465e+06\n",
            "2023-07-21    44851.767767  1.396203e+06\n",
            "2023-07-24    44827.773206  1.382002e+06\n",
            "2023-07-25    44509.683869  1.372565e+06\n",
            "2023-07-26    44764.774118  1.394174e+06\n",
            "\n",
            "[1254 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}